{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-547ER22Qr6"
      },
      "outputs": [],
      "source": [
        "#A Study on Efficiency, Accuracy and Document Structure for Answer Sentence Selection\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "QUESTION_LEN = 23\n",
        "CANDIDATE_LEN = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuFyVPpK2ZOU",
        "outputId": "9b76b37e-6eec-4544-ace2-414927fe088a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd \"/content/drive/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dN91w0gi2Qr-"
      },
      "source": [
        "## Number Batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LSeBMhl2QsA",
        "outputId": "3dbc75e5-edd1-444a-8838-46dcc91c5144"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wordfreq in /usr/local/lib/python3.7/dist-packages (3.0.3)\n",
            "Requirement already satisfied: ftfy>=6.1 in /usr/local/lib/python3.7/dist-packages (from wordfreq) (6.1.1)\n",
            "Requirement already satisfied: regex>=2021.7.6 in /usr/local/lib/python3.7/dist-packages (from wordfreq) (2022.6.2)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.7/dist-packages (from wordfreq) (1.0.4)\n",
            "Requirement already satisfied: langcodes>=3.0 in /usr/local/lib/python3.7/dist-packages (from wordfreq) (3.3.0)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy>=6.1->wordfreq) (0.2.5)\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "This Python module provides just the code from the 'conceptnet5' module that\n",
        "you need to represent terms, possibly with multiple words, as ConceptNet URIs.\n",
        "\n",
        "It depends on 'wordfreq', a Python 3 library, so it can tokenize multilingual\n",
        "text consistently: https://pypi.org/project/wordfreq/\n",
        "\n",
        "Example:\n",
        "\n",
        ">>> standardized_uri('es', 'ayudar')\n",
        "'/c/es/ayudar'\n",
        ">>> standardized_uri('en', 'a test phrase')\n",
        "'/c/en/test_phrase'\n",
        ">>> standardized_uri('en', '24 hours')\n",
        "'/c/en/##_hours'\n",
        "\"\"\"\n",
        "!pip install wordfreq\n",
        "import wordfreq\n",
        "import re\n",
        "\n",
        "\n",
        "# English-specific stopword handling\n",
        "STOPWORDS = ['the', 'a', 'an']\n",
        "DROP_FIRST = ['to']\n",
        "DOUBLE_DIGIT_RE = re.compile(r'[0-9][0-9]')\n",
        "DIGIT_RE = re.compile(r'[0-9]')\n",
        "\n",
        "\n",
        "def standardized_uri(language, term):\n",
        "    \"\"\"\n",
        "    Get a URI that is suitable to label a row of a vector space, by making sure\n",
        "    that both ConceptNet's and word2vec's normalizations are applied to it.\n",
        "\n",
        "    'language' should be a BCP 47 language code, such as 'en' for English.\n",
        "\n",
        "    If the term already looks like a ConceptNet URI, it will only have its\n",
        "    sequences of digits replaced by #. Otherwise, it will be turned into a\n",
        "    ConceptNet URI in the given language, and then have its sequences of digits\n",
        "    replaced.\n",
        "    \"\"\"\n",
        "    if not (term.startswith('/') and term.count('/') >= 2):\n",
        "        term = _standardized_concept_uri(language, term)\n",
        "    return replace_numbers(term)\n",
        "\n",
        "\n",
        "def english_filter(tokens):\n",
        "    \"\"\"\n",
        "    Given a list of tokens, remove a small list of English stopwords. This\n",
        "    helps to work with previous versions of ConceptNet, which often provided\n",
        "    phrases such as 'an apple' and assumed they would be standardized to\n",
        "\t'apple'.\n",
        "    \"\"\"\n",
        "    non_stopwords = [token for token in tokens if token not in STOPWORDS]\n",
        "    while non_stopwords and non_stopwords[0] in DROP_FIRST:\n",
        "        non_stopwords = non_stopwords[1:]\n",
        "    if non_stopwords:\n",
        "        return non_stopwords\n",
        "    else:\n",
        "        return tokens\n",
        "\n",
        "\n",
        "def replace_numbers(s):\n",
        "    \"\"\"\n",
        "    Replace digits with # in any term where a sequence of two digits appears.\n",
        "\n",
        "    This operation is applied to text that passes through word2vec, so we\n",
        "    should match it.\n",
        "    \"\"\"\n",
        "    if DOUBLE_DIGIT_RE.search(s):\n",
        "        return DIGIT_RE.sub('#', s)\n",
        "    else:\n",
        "        return s\n",
        "\n",
        "\n",
        "def _standardized_concept_uri(language, term):\n",
        "    if language == 'en':\n",
        "        token_filter = english_filter\n",
        "    else:\n",
        "        token_filter = None\n",
        "    language = language.lower()\n",
        "    norm_text = _standardized_text(term, token_filter)\n",
        "    return '/c/{}/{}'.format(language, norm_text)\n",
        "    # return ''.format(language, norm_text)\n",
        "\n",
        "\n",
        "def _standardized_text(text, token_filter):\n",
        "    tokens = simple_tokenize(text.replace('_', ' '))\n",
        "    if token_filter is not None:\n",
        "        tokens = token_filter(tokens)\n",
        "    return '_'.join(tokens)\n",
        "\n",
        "\n",
        "def simple_tokenize(text):\n",
        "    \"\"\"\n",
        "    Tokenize text using the default wordfreq rules.\n",
        "    \"\"\"\n",
        "    return wordfreq.tokenize(text, 'xx')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bjDsyus2QsC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "embedding_dict = {}\n",
        "word_dict={}\n",
        "limit = 0\n",
        "with open(\"numberbatch-en.txt\", 'r') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.asarray(values[1:], \"float32\")\n",
        "        embedding_dict[word] = vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjFBh63k2QsD"
      },
      "outputs": [],
      "source": [
        "#given a word, standardise it and return the embedding\n",
        "def get_embedding(word):\n",
        "    word = standardized_uri('en', word)\n",
        "    #truncate first 6 characters\n",
        "    word = word[6:]\n",
        "    if word in embedding_dict:\n",
        "        return embedding_dict[word]\n",
        "    else:\n",
        "        return np.ones(300, dtype=np.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mUXqqao2QsE"
      },
      "source": [
        "## DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YusBIXry2QsF",
        "outputId": "1c458580-14c6-4891-d681-5cc34afbed46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train size :  (20347, 7)\n",
            "test size :  (6116, 7)\n",
            "dev size :  (2733, 7)\n"
          ]
        }
      ],
      "source": [
        "df_train = pd.read_csv('WikiQACorpus/WikiQA-train.tsv', sep='\\t')\n",
        "df_train.head(30)\n",
        "\n",
        "df_test = pd.read_csv('WikiQACorpus/WikiQA-test.tsv', sep='\\t')\n",
        "df_test.head(30)\n",
        "\n",
        "df_dev = pd.read_csv('WikiQACorpus/WikiQA-dev.tsv', sep='\\t')\n",
        "df_dev.head(30)\n",
        "\n",
        "print(\"train size : \",df_train.shape)\n",
        "print(\"test size : \",df_test.shape)\n",
        "print(\"dev size : \",df_dev.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHqm3EAT2QsH"
      },
      "outputs": [],
      "source": [
        "# for each Question, sentence, remove special characters\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text\n",
        "\n",
        "df_train['Question'] = df_train['Question'].apply(lambda x: clean_text(x))\n",
        "df_train['Sentence'] = df_train['Sentence'].apply(lambda x: clean_text(x))\n",
        "\n",
        "df_dev['Question'] = df_dev['Question'].apply(lambda x: clean_text(x))\n",
        "df_dev['Sentence'] = df_dev['Sentence'].apply(lambda x: clean_text(x))\n",
        "\n",
        "df_test['Question'] = df_test['Question'].apply(lambda x: clean_text(x))\n",
        "df_test['Sentence'] = df_test['Sentence'].apply(lambda x: clean_text(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uEitvowp2QsI"
      },
      "outputs": [],
      "source": [
        "#for each question, find the number of the words in the question\n",
        "def get_question_length(row):\n",
        "    return len(row['Question'].split())\n",
        "\n",
        "def get_sentence_length(row):\n",
        "    return len(row['Sentence'].split())\n",
        "\n",
        "df_train['Question_length'] = df_train.apply(get_question_length, axis=1)\n",
        "df_train['Candidate_length'] = df_train.apply(get_sentence_length, axis=1)\n",
        "df_train = df_train.drop(['DocumentID', 'DocumentTitle', 'SentenceID'], axis=1)\n",
        "\n",
        "df_test['Question_length'] = df_test.apply(get_question_length, axis=1)\n",
        "df_test['Candidate_length'] = df_test.apply(get_sentence_length, axis=1)\n",
        "df_test = df_test.drop(['DocumentID', 'DocumentTitle', 'SentenceID'], axis=1)\n",
        "\n",
        "df_dev['Question_length'] = df_dev.apply(get_question_length, axis=1)\n",
        "df_dev['Candidate_length'] = df_dev.apply(get_sentence_length, axis=1)\n",
        "df_dev = df_dev.drop(['DocumentID', 'DocumentTitle', 'SentenceID'], axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xw4zV96K2QsJ",
        "outputId": "4691c53c-1e0a-4738-eefa-c7d8f8a91b08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max question length in train data set:  23\n",
            "Max candidate length in train data set:  305\n",
            "Number of unique questions in train data set:  2117\n",
            "Total number of candidates in train data set:  20347\n"
          ]
        }
      ],
      "source": [
        "# find the maximum length of the question and the candidate sentence\n",
        "max_question_length = df_train['Question_length'].max()\n",
        "max_candidate_length = df_train['Candidate_length'].max()\n",
        "#find the number of unique questions \n",
        "unique_questions = df_train['QuestionID'].unique()\n",
        "print(\"Max question length in train data set: \", max_question_length)\n",
        "print(\"Max candidate length in train data set: \", max_candidate_length)\n",
        "print(\"Number of unique questions in train data set: \", len(unique_questions))\n",
        "\n",
        "total_candidates = len(df_train)\n",
        "print(\"Total number of candidates in train data set: \", total_candidates)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "va4sNbYU2QsJ",
        "outputId": "76a3e0e5-e63e-4728-82d0-76163bb8499e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train size :  (20251, 6)\n",
            "test size :  (6092, 6)\n",
            "dev size :  (2722, 6)\n"
          ]
        }
      ],
      "source": [
        "# delete the row if sentence length is greater than 50 and label is 0\n",
        "\n",
        "df_train = df_train.drop(df_train[(df_train['Label'] == 0) & (df_train['Candidate_length'] > CANDIDATE_LEN)].index)\n",
        "df_test = df_test.drop(df_test[(df_test['Label'] == 0) & (df_test['Candidate_length'] > CANDIDATE_LEN)].index)\n",
        "df_dev = df_dev.drop(df_dev[(df_dev['Label'] == 0) & (df_dev['Candidate_length'] > CANDIDATE_LEN)].index)\n",
        "\n",
        "\n",
        "\n",
        "print(\"train size : \",df_train.shape)\n",
        "print(\"test size : \",df_test.shape)\n",
        "print(\"dev size : \",df_dev.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9XIklpa2QsK",
        "outputId": "f0ae1b37-3eed-4704-cf5e-48ec01f28647"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of unique questions in train data set:  2112\n",
            "Number of unique questions in test data set:  628\n",
            "Number of unique questions in dev data set:  295\n"
          ]
        }
      ],
      "source": [
        "QuestionID_greater_than_CANDIDATE_LEN = []\n",
        "\n",
        "# for candidate if length is greater than CANDIDATE_LEN, add the question id to the list\n",
        "for index, row in df_train.iterrows():\n",
        "    if row['Candidate_length'] > CANDIDATE_LEN:\n",
        "        QuestionID_greater_than_CANDIDATE_LEN.append(row['QuestionID'])\n",
        "\n",
        "# delete the rows where the question id is in the list\n",
        "df_train = df_train[~df_train['QuestionID'].isin(QuestionID_greater_than_CANDIDATE_LEN)]\n",
        "\n",
        "#print the nubmer of unique questions\n",
        "unique_questions = df_train['QuestionID'].unique()\n",
        "print(\"Number of unique questions in train data set: \", len(unique_questions))\n",
        "\n",
        "\n",
        "QuestionID_greater_than_CANDIDATE_LEN = []\n",
        "\n",
        "# for candidate if length is greater than CANDIDATE_LEN, add the question id to the list\n",
        "for index, row in df_test.iterrows():\n",
        "    if row['Candidate_length'] > CANDIDATE_LEN:\n",
        "        QuestionID_greater_than_CANDIDATE_LEN.append(row['QuestionID'])\n",
        "\n",
        "# delete the rows where the question id is in the list\n",
        "df_test = df_test[~df_test['QuestionID'].isin(QuestionID_greater_than_CANDIDATE_LEN)]\n",
        "\n",
        "#print the nubmer of unique questions\n",
        "unique_questions = df_test['QuestionID'].unique()\n",
        "print(\"Number of unique questions in test data set: \", len(unique_questions))\n",
        "\n",
        "QuestionID_greater_than_CANDIDATE_LEN = []\n",
        "\n",
        "# for candidate if length is greater than CANDIDATE_LEN, add the question id to the list\n",
        "for index, row in df_dev.iterrows():\n",
        "    if row['Candidate_length'] > CANDIDATE_LEN:\n",
        "        QuestionID_greater_than_CANDIDATE_LEN.append(row['QuestionID'])\n",
        "\n",
        "# delete the rows where the question id is in the list\n",
        "df_dev = df_dev[~df_dev['QuestionID'].isin(QuestionID_greater_than_CANDIDATE_LEN)]\n",
        "\n",
        "#print the nubmer of unique questions\n",
        "unique_questions = df_dev['QuestionID'].unique()\n",
        "print(\"Number of unique questions in dev data set: \", len(unique_questions))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKvtTRgf2QsL",
        "outputId": "bd059895-dff6-4396-8beb-cc0bdeadecc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max question length in train dataset:  23\n",
            "Max candidate length in train dataset:  64\n",
            "Max question length in test dataset:  19\n",
            "Max candidate length in test dataset:  64\n",
            "Max question length in dev dataset:  21\n",
            "Max candidate length in dev dataset:  63\n"
          ]
        }
      ],
      "source": [
        "# dind the maximum length of the question and the candidate sentence\n",
        "max_question_length = df_train['Question_length'].max()\n",
        "max_candidate_length = df_train['Candidate_length'].max()\n",
        "\n",
        "print(\"Max question length in train dataset: \", max_question_length)\n",
        "print(\"Max candidate length in train dataset: \", max_candidate_length)\n",
        "\n",
        "# dind the maximum length of the question and the candidate sentence\n",
        "max_question_length = df_test['Question_length'].max()\n",
        "max_candidate_length = df_test['Candidate_length'].max()\n",
        "\n",
        "print(\"Max question length in test dataset: \", max_question_length)\n",
        "print(\"Max candidate length in test dataset: \", max_candidate_length)\n",
        "\n",
        "# dind the maximum length of the question and the candidate sentence\n",
        "max_question_length = df_dev['Question_length'].max()\n",
        "max_candidate_length = df_dev['Candidate_length'].max()\n",
        "\n",
        "print(\"Max question length in dev dataset: \", max_question_length)\n",
        "print(\"Max candidate length in dev dataset: \", max_candidate_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ay__kaK02QsL"
      },
      "outputs": [],
      "source": [
        "# reformat the data where each question has a list of candidate sentences and a list of labels\n",
        "# 1 if the sentence is the answer, 0 otherwise\n",
        "def reformat_data(df):\n",
        "    questions = []\n",
        "    candidates = []\n",
        "    labels = []\n",
        "    for index, row in df.iterrows():\n",
        "        if row['Question'] not in questions:\n",
        "            questions.append(row['Question'])\n",
        "            candidates.append([row['Sentence']])\n",
        "            labels.append([row['Label']])\n",
        "        else:\n",
        "            candidates[questions.index(row['Question'])].append(row['Sentence'])\n",
        "            labels[questions.index(row['Question'])].append(row['Label'])\n",
        "    return questions, candidates, labels\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ck00yyj2QsL",
        "outputId": "ee27ca9a-3d7d-4c68-9d87-a129ba862404"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "23\n",
            "64\n"
          ]
        }
      ],
      "source": [
        "text_questions_train, text_candidates_train, labels_train = reformat_data(df_train)\n",
        "text_questions_test, text_candidates_test, labels_test = reformat_data(df_test)\n",
        "text_questions_dev, text_candidates_dev, labels_dev = reformat_data(df_dev)\n",
        "\n",
        "max_question_length = QUESTION_LEN\n",
        "max_candidate_length = CANDIDATE_LEN\n",
        "print(max_question_length)\n",
        "print(max_candidate_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5GpLKiw2QsM"
      },
      "outputs": [],
      "source": [
        "emb_questions_train = []\n",
        "emb_candidates_train = []\n",
        "\n",
        "# get the embedding for each word in the question and candidate sentence using the get_embedding function\n",
        "for question in text_questions_train:\n",
        "    emb_questions_train.append([get_embedding(word) for word in question.split()])\n",
        "for candidate in text_candidates_train:\n",
        "    emb_candidates_train.append([[get_embedding(word) for word in sentence.split()] for sentence in candidate])\n",
        "\n",
        "emb_questions_test = []\n",
        "emb_candidates_test = []\n",
        "\n",
        "# get the embedding for each word in the question and candidate sentence using the get_embedding function\n",
        "for question in text_questions_test:\n",
        "    emb_questions_test.append([get_embedding(word) for word in question.split()])\n",
        "for candidate in text_candidates_test:\n",
        "    emb_candidates_test.append([[get_embedding(word) for word in sentence.split()] for sentence in candidate])\n",
        "\n",
        "emb_questions_dev = []\n",
        "emb_candidates_dev = []\n",
        "\n",
        "# get the embedding for each word in the question and candidate sentence using the get_embedding function\n",
        "for question in text_questions_dev:\n",
        "    emb_questions_dev.append([get_embedding(word) for word in question.split()])\n",
        "for candidate in text_candidates_dev:\n",
        "    emb_candidates_dev.append([[get_embedding(word) for word in sentence.split()] for sentence in candidate])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTBPDvrn2QsM",
        "outputId": "1414534e-4028-4f4d-d981-261d1c447a97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of candidates train dataset:  20220\n",
            "Total number of questions train dataset:  2112\n"
          ]
        }
      ],
      "source": [
        "# print the total number of candidates for all questions\n",
        "total_candidates_train = 0\n",
        "for candidate in emb_candidates_train:\n",
        "    total_candidates_train += len(candidate)\n",
        "print(\"Total number of candidates train dataset: \", total_candidates_train)\n",
        "\n",
        "print(\"Total number of questions train dataset: \", len(emb_questions_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mMtTr7L2QsN",
        "outputId": "a5605855-b856-45ee-d470-f94c73f9c605"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of candidates in train dataset:  8592\n",
            "Total number of questions in train dataset:  867\n"
          ]
        }
      ],
      "source": [
        "# if all the labels are zero, remove the question and candidate sentence\n",
        "def remove_all_zeros(labels,emb_questions,emb_candidates):\n",
        "  for i in range(len(labels)):\n",
        "      if sum(labels[i]) == 0:\n",
        "          emb_questions[i] = []\n",
        "          emb_candidates[i] = []\n",
        "          labels[i] = []\n",
        "\n",
        "  # remove the empty lists\n",
        "  return [x for x in emb_questions if x != []] ,[x for x in emb_candidates if x != []] ,[x for x in labels if x != []]\n",
        "\n",
        "emb_questions_train,emb_candidates_train,labels_train = remove_all_zeros(labels_train,emb_questions_train,emb_candidates_train)\n",
        "emb_questions_test,emb_candidates_test,labels_test = remove_all_zeros(labels_test,emb_questions_test,emb_candidates_test)\n",
        "emb_questions_dev,emb_candidates_dev,labels_dev = remove_all_zeros(labels_dev,emb_questions_dev,emb_candidates_dev)\n",
        "\n",
        "# print the total number of candidates for all questions\n",
        "total_candidates = 0\n",
        "for candidate in emb_candidates_train:\n",
        "    total_candidates += len(candidate)\n",
        "print(\"Total number of candidates in train dataset: \", total_candidates)\n",
        "\n",
        "print(\"Total number of questions in train dataset: \", len(emb_questions_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5uCd7ZJ2QsN"
      },
      "outputs": [],
      "source": [
        "# for each question, candiate sentence pair, perform a cosinet between each embedding of question to each embedding of sentence to identify the most similar word\n",
        "\n",
        "def get_cosine_similarity(emb_question, emb_candidate):\n",
        "    question_cosines = []\n",
        "    candidate_cosines = []\n",
        "    # for each word in question, find the word in the candidate sentence that is most similar and calculate the maximum cosine similarity\n",
        "    for word in emb_question:\n",
        "        question_cosines.append(max([np.dot(word, candidate_word)/(np.linalg.norm(word)*np.linalg.norm(candidate_word)) for candidate_word in emb_candidate]))\n",
        "        \n",
        "\n",
        "    for word in emb_candidate:\n",
        "        candidate_cosines.append(max([np.dot(word, question_word)/(np.linalg.norm(word)*np.linalg.norm(question_word)) for question_word in emb_question]))\n",
        "        \n",
        "\n",
        "    return question_cosines, candidate_cosines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jH_LpbIv2QsN"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "\n",
        "def embeddings_q_c_l(emb_questions,emb_candidates,labels):\n",
        "  r_emb_question_candidate_pairs = []\n",
        "\n",
        "\n",
        "  # for each question, candidate sentence pair, get the cosine similarity between each word in the question and each word in the candidate sentence\n",
        "  # append the cosine similarity values to each question and candidate sentence embedding\n",
        "  for i in range(len(emb_questions)):\n",
        "      temp = []\n",
        "      for j in range(len(emb_candidates[i])):\n",
        "          question_cosines, candidate_cosines = get_cosine_similarity(emb_questions[i], emb_candidates[i][j])\n",
        "\n",
        "          # take a deep copy of emb_question[i]\n",
        "          temp_emb_question = copy.deepcopy(emb_questions[i])\n",
        "          temp_emb_candidate = copy.deepcopy(emb_candidates[i][j])\n",
        "          for k in range(len(temp_emb_question)):\n",
        "              temp_emb_question[k] = np.append(temp_emb_question[k], question_cosines[k])\n",
        "          for k in range(len(temp_emb_candidate)):\n",
        "              temp_emb_candidate[k] = np.append(temp_emb_candidate[k], candidate_cosines[k])\n",
        "          temp.append([temp_emb_question, temp_emb_candidate, labels[i][j]])\n",
        "      r_emb_question_candidate_pairs.append(temp)\n",
        "  return r_emb_question_candidate_pairs\n",
        "\n",
        "r_emb_question_candidate_pairs_train = embeddings_q_c_l(emb_questions_train,emb_candidates_train,labels_train)\n",
        "r_emb_question_candidate_pairs_test = embeddings_q_c_l(emb_questions_test,emb_candidates_test,labels_test)\n",
        "r_emb_question_candidate_pairs_dev = embeddings_q_c_l(emb_questions_dev,emb_candidates_dev,labels_dev)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GW9Cmarv2QsO"
      },
      "outputs": [],
      "source": [
        "#pad the sentence based on given required length from the r_emb_question_candidate_pairs\n",
        "def pad_sentence_embedding(sentence_embedding, required_length):\n",
        "\n",
        "    if len(sentence_embedding) < required_length:\n",
        "        for i in range(required_length - len(sentence_embedding)):\n",
        "            sentence_embedding.append(np.zeros(len(sentence_embedding[0])))\n",
        "\n",
        "    return sentence_embedding\n",
        "\n",
        "\n",
        "# pad the question and candidate sentence embedding based on the max length of the question and candidate sentence\n",
        "def get_pr_emb_question_candidate_pairs(r_emb_question_candidate_pairs):\n",
        "  pr_emb_question_candidate_pairs = []\n",
        "  for entry in r_emb_question_candidate_pairs:\n",
        "      temp = []\n",
        "      for question, candidate, label in entry:\n",
        "          temp.append([pad_sentence_embedding(question, max_question_length), pad_sentence_embedding(candidate, max_candidate_length), label])\n",
        "      pr_emb_question_candidate_pairs.append(temp)\n",
        "  return pr_emb_question_candidate_pairs\n",
        "\n",
        "pr_emb_question_candidate_pairs_train = get_pr_emb_question_candidate_pairs(r_emb_question_candidate_pairs_train)\n",
        "pr_emb_question_candidate_pairs_test = get_pr_emb_question_candidate_pairs(r_emb_question_candidate_pairs_test)\n",
        "pr_emb_question_candidate_pairs_dev = get_pr_emb_question_candidate_pairs(r_emb_question_candidate_pairs_dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8JLPQV1K2QsP"
      },
      "outputs": [],
      "source": [
        "# change every list into a numpy array\n",
        "for i in range(len(pr_emb_question_candidate_pairs_train)):\n",
        "    for j in range(len(pr_emb_question_candidate_pairs_train[i])):\n",
        "        pr_emb_question_candidate_pairs_train[i][j][0] = np.asarray(pr_emb_question_candidate_pairs_train[i][j][0], dtype=np.float32)\n",
        "        pr_emb_question_candidate_pairs_train[i][j][1] = np.asarray(pr_emb_question_candidate_pairs_train[i][j][1], dtype=np.float32)\n",
        "\n",
        "for i in range(len(pr_emb_question_candidate_pairs_test)):\n",
        "    for j in range(len(pr_emb_question_candidate_pairs_test[i])):\n",
        "        pr_emb_question_candidate_pairs_test[i][j][0] = np.asarray(pr_emb_question_candidate_pairs_test[i][j][0], dtype=np.float32)\n",
        "        pr_emb_question_candidate_pairs_test[i][j][1] = np.asarray(pr_emb_question_candidate_pairs_test[i][j][1], dtype=np.float32)\n",
        "\n",
        "for i in range(len(pr_emb_question_candidate_pairs_dev)):\n",
        "    for j in range(len(pr_emb_question_candidate_pairs_dev[i])):\n",
        "        pr_emb_question_candidate_pairs_dev[i][j][0] = np.asarray(pr_emb_question_candidate_pairs_dev[i][j][0], dtype=np.float32)\n",
        "        pr_emb_question_candidate_pairs_dev[i][j][1] = np.asarray(pr_emb_question_candidate_pairs_dev[i][j][1], dtype=np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqaXvHCV2QsP",
        "outputId": "8fc8296e-534f-4763-9676-5f15d04e72c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of question embedding:  (23, 301)\n",
            "Shape of candidate embedding:  (64, 301)\n",
            "Number of questions:  867\n",
            "Number of Questions:  867\n"
          ]
        }
      ],
      "source": [
        "# find the shape of the question and candidate sentence embedding\n",
        "# print the number of questions and number of candidates for each question\n",
        "print(\"Shape of question embedding: \", pr_emb_question_candidate_pairs_train[0][0][0].shape)\n",
        "print(\"Shape of candidate embedding: \", pr_emb_question_candidate_pairs_train[0][0][1].shape)\n",
        "print(\"Number of questions: \", len(pr_emb_question_candidate_pairs_train))\n",
        "print(\"Number of Questions: \", len(pr_emb_question_candidate_pairs_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWr6-bwP2QsQ"
      },
      "outputs": [],
      "source": [
        "# save list as a pickle file and load\n",
        "import pickle\n",
        "\n",
        "def save_pickle(obj, path):\n",
        "    with open(path, 'wb') as f:\n",
        "        pickle.dump(obj, f)\n",
        "\n",
        "def load_pickle(path):\n",
        "    with open(path, 'rb') as f:\n",
        "        return pickle.load(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ko-i-Ppz2QsQ"
      },
      "outputs": [],
      "source": [
        "save_pickle(pr_emb_question_candidate_pairs_train,'./qc_embeddings_train_paper1.pkl')\n",
        "save_pickle(pr_emb_question_candidate_pairs_test,'./qc_embeddings_test_paper1.pkl')\n",
        "save_pickle(pr_emb_question_candidate_pairs_dev,'./qc_embeddings_dev_paper1.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_HigJ-NbiGp",
        "outputId": "34c584ea-bac4-4f03-a5c3-a0bf547270f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1E5PWclbU-m"
      },
      "outputs": [],
      "source": [
        "# load a pickle file to a list\n",
        "import pickle\n",
        "# load a pickle file to a list\n",
        "import pickle\n",
        "def load_pickle(filename):\n",
        "    with open(filename, 'rb') as f:\n",
        "        return pickle.load(f)\n",
        "\n",
        "def load_pickle(filename):\n",
        "    with open(filename, 'rb') as f:\n",
        "        return pickle.load(f)\n",
        "\n",
        "pr_emb_question_candidate_pairs_train = load_pickle(\"qc_embeddings_train_paper1.pkl\")\n",
        "pr_emb_question_candidate_pairs_test = load_pickle(\"qc_embeddings_test_paper1.pkl\")\n",
        "pr_emb_question_candidate_pairs_dev = load_pickle(\"qc_embeddings_dev_paper1.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFI4jJPAcCxz"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUd0dVMnXfCG"
      },
      "outputs": [],
      "source": [
        "# convert pr_emb_question_candidate_pairs to list of question_embedding, candidate_embedding, label\n",
        "\n",
        "# list of question_embedding, candidate_embedding, label\n",
        "def convert_to_qcl(pr_emb_question_candidate_pairs):\n",
        "  qcl = []\n",
        "\n",
        "  for i in range(len(pr_emb_question_candidate_pairs)):\n",
        "      for j in range(len(pr_emb_question_candidate_pairs[i])):\n",
        "          qcl.append([np.array(pr_emb_question_candidate_pairs[i][j][0]), np.array(pr_emb_question_candidate_pairs[i][j][1]), np.array(pr_emb_question_candidate_pairs[i][j][2])])\n",
        "  return qcl\n",
        "\n",
        "qcl_train = convert_to_qcl(pr_emb_question_candidate_pairs_train)\n",
        "qcl_test = convert_to_qcl(pr_emb_question_candidate_pairs_test)\n",
        "qcl_dev = convert_to_qcl(pr_emb_question_candidate_pairs_dev)\n",
        "\n",
        "def seperate_qcl(qcl):\n",
        "  questions_emb = []\n",
        "  candidates_emb = []\n",
        "  labels = []\n",
        "\n",
        "  for i in range(len(qcl)):\n",
        "      questions_emb.append(qcl[i][0])\n",
        "      candidates_emb.append(qcl[i][1])\n",
        "      labels.append(qcl[i][2])\n",
        "\n",
        "\n",
        "  questions_emb = np.array(questions_emb)\n",
        "  candidates_emb = np.array(candidates_emb)\n",
        "  labels = np.array(labels)\n",
        "\n",
        "  return questions_emb,candidates_emb,labels\n",
        "\n",
        "questions_emb_train,candidates_emb_train,labels_train = seperate_qcl(qcl_train)\n",
        "questions_emb_test,candidates_emb_test,labels_test = seperate_qcl(qcl_test)\n",
        "questions_emb_dev,candidates_emb_dev,labels_dev = seperate_qcl(qcl_dev)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgup8KVzYyoV",
        "outputId": "8d7b6201-90ef-42c9-d333-7f1b193e6fe9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(8592,)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UlvoTHf96EOv"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.utils.data as data_utils\n",
        "import torch.nn.utils.rnn as rnn_utils\n",
        "import random\n",
        "\n",
        "class CNN_RNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN_RNN, self).__init__()\n",
        "        # question size (301,32)\n",
        "        # candidate size (301,64)\n",
        "        \n",
        "        # apply conv2d on question embedding with kernel size 5\n",
        "        self.conv1 = nn.Conv2d(1, 1, 5)\n",
        "        # apply conv2d on candidate embedding with kernel size 5\n",
        "        self.conv2 = nn.Conv2d(1, 1, 5)\n",
        "\n",
        "        # output size of conv1 = (301-5+1, 32-5+1) = (297, 28)\n",
        "        # output size of conv2 = (301-5+1, 64-5+1) = (297, 60)\n",
        "\n",
        "        # apply global max pooling along such that the size is (297,1)\n",
        "        self.pool1 = nn.MaxPool2d((1, QUESTION_LEN-5+1))\n",
        "        self.pool2 = nn.MaxPool2d((1, CANDIDATE_LEN-5+1))\n",
        "\n",
        "        # output size of pool1 = (297,1)\n",
        "        # output size of pool2 = (297,1)\n",
        "\n",
        "        # concatenate the output of pool1 and pool2 \n",
        "        # output size of concat = (297+297, 1) = (594, 1)\n",
        "\n",
        "        # apply RNN on the concatenated output\n",
        "        self.rnn = nn.RNN(594, 594, 1, batch_first=True)\n",
        "\n",
        "        # classify the output of RNN as two classes\n",
        "        self.fc = nn.Linear(594, 2)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self,q,c):\n",
        "        # q = q.view(-1, 1, 301, 32)\n",
        "        # c = c.view(-1, 1, 301, 64)\n",
        "        q = q.view(-1, 1, 301, QUESTION_LEN)\n",
        "        c = c.view(-1, 1, 301, CANDIDATE_LEN)\n",
        "        q = F.relu(self.conv1(q))\n",
        "        c = F.relu(self.conv2(c))\n",
        "        q = self.pool1(q)\n",
        "        c = self.pool2(c)\n",
        "        q = q.view(-1, 297)\n",
        "        c = c.view(-1, 297)\n",
        "        mul = torch.mul(q,c)\n",
        "        sub = torch.sub(q,c)\n",
        "        x = torch.cat((mul,sub),1)\n",
        "        # x size = (1, 594)\n",
        "        x = x.view(-1, 1, 594)\n",
        "        x, _ = self.rnn(x)\n",
        "        x = x.view(-1, 594)\n",
        "        x = self.fc(x)\n",
        "        # x size = (-1, 2)\n",
        "        return x\n",
        "\n",
        "\n",
        "class CNN_BiRNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN_BiRNN, self).__init__()\n",
        "        # question size (301,32)\n",
        "        # candidate size (301,64)\n",
        "        \n",
        "        # apply conv2d on question embedding with kernel size 5\n",
        "        self.conv1 = nn.Conv2d(1, 1, 5)\n",
        "        # apply conv2d on candidate embedding with kernel size 5\n",
        "        self.conv2 = nn.Conv2d(1, 1, 5)\n",
        "\n",
        "        # output size of conv1 = (301-5+1, 32-5+1) = (297, 28)\n",
        "        # output size of conv2 = (301-5+1, 64-5+1) = (297, 60)\n",
        "\n",
        "        # apply global max pooling along such that the size is (297,1)\n",
        "        self.pool1 = nn.MaxPool2d((1, QUESTION_LEN-5+1))\n",
        "        self.pool2 = nn.MaxPool2d((1, CANDIDATE_LEN-5+1))\n",
        "\n",
        "        # output size of pool1 = (297,1)\n",
        "        # output size of pool2 = (297,1)\n",
        "\n",
        "        # concatenate the output of pool1 and pool2 \n",
        "        # output size of concat = (297+297, 1) = (594, 1)\n",
        "\n",
        "        # apply RNN on the concatenated output\n",
        "        self.rnn = nn.RNN(594, 594, 1, batch_first=True,bidirectional=True)\n",
        "\n",
        "        # classify the output of RNN as two classes\n",
        "        self.fc = nn.Linear(2*594, 2)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self,q,c):\n",
        "        # q = q.view(-1, 1, 301, 32)\n",
        "        # c = c.view(-1, 1, 301, 64)\n",
        "        q = q.view(-1, 1, 301, QUESTION_LEN)\n",
        "        c = c.view(-1, 1, 301, CANDIDATE_LEN)\n",
        "        q = F.relu(self.conv1(q))\n",
        "        c = F.relu(self.conv2(c))\n",
        "        q = self.pool1(q)\n",
        "        c = self.pool2(c)\n",
        "        q = q.view(-1, 297)\n",
        "        c = c.view(-1, 297)\n",
        "        mul = torch.mul(q,c)\n",
        "        sub = torch.sub(q,c)\n",
        "        x = torch.cat((mul,sub),1)\n",
        "        # x size = (1, 594)\n",
        "        x = x.view(-1, 1, 594)\n",
        "        x, _ = self.rnn(x)\n",
        "        x = x.view(-1, 2*594)\n",
        "        x = self.fc(x)\n",
        "        # x size = (-1, 2)\n",
        "        return x\n",
        "\n",
        "class CNN_LSTM(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN_LSTM, self).__init__()\n",
        "        # question size (301,32)\n",
        "        # candidate size (301,64)\n",
        "        \n",
        "        # apply conv2d on question embedding with kernel size 5\n",
        "        self.conv1 = nn.Conv2d(1, 1, 5)\n",
        "        # apply conv2d on candidate embedding with kernel size 5\n",
        "        self.conv2 = nn.Conv2d(1, 1, 5)\n",
        "\n",
        "        # output size of conv1 = (301-5+1, 32-5+1) = (297, 28)\n",
        "        # output size of conv2 = (301-5+1, 64-5+1) = (297, 60)\n",
        "\n",
        "        # apply global max pooling along such that the size is (297,1)\n",
        "        self.pool1 = nn.MaxPool2d((1, QUESTION_LEN-5+1))\n",
        "        self.pool2 = nn.MaxPool2d((1, CANDIDATE_LEN-5+1))\n",
        "\n",
        "        # output size of pool1 = (297,1)\n",
        "        # output size of pool2 = (297,1)\n",
        "\n",
        "        # concatenate the output of pool1 and pool2 \n",
        "        # output size of concat = (297+297, 1) = (594, 1)\n",
        "\n",
        "        # apply RNN on the concatenated output\n",
        "        self.rnn = nn.LSTM(594, 594, 1, batch_first=True)\n",
        "\n",
        "        # classify the output of RNN as two classes\n",
        "        self.fc = nn.Linear(594, 2)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self,q,c):\n",
        "        # q = q.view(-1, 1, 301, 32)\n",
        "        # c = c.view(-1, 1, 301, 64)\n",
        "        q = q.view(-1, 1, 301, QUESTION_LEN)\n",
        "        c = c.view(-1, 1, 301, CANDIDATE_LEN)\n",
        "        q = F.relu(self.conv1(q))\n",
        "        c = F.relu(self.conv2(c))\n",
        "        q = self.pool1(q)\n",
        "        c = self.pool2(c)\n",
        "        q = q.view(-1, 297)\n",
        "        c = c.view(-1, 297)\n",
        "        mul = torch.mul(q,c)\n",
        "        sub = torch.sub(q,c)\n",
        "        x = torch.cat((mul,sub),1)\n",
        "        # x size = (1, 594)\n",
        "        x = x.view(-1, 1, 594)\n",
        "        x, _ = self.rnn(x)\n",
        "        x = x.view(-1, 594)\n",
        "        x = self.fc(x)\n",
        "        # x size = (-1, 2)\n",
        "        return x\n",
        "\n",
        "\n",
        "class CNN_BiLSTM(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN_BiLSTM, self).__init__()\n",
        "        # question size (301,32)\n",
        "        # candidate size (301,64)\n",
        "        \n",
        "        # apply conv2d on question embedding with kernel size 5\n",
        "        self.conv1 = nn.Conv2d(1, 1, 5)\n",
        "        # apply conv2d on candidate embedding with kernel size 5\n",
        "        self.conv2 = nn.Conv2d(1, 1, 5)\n",
        "\n",
        "        # output size of conv1 = (301-5+1, 32-5+1) = (297, 28)\n",
        "        # output size of conv2 = (301-5+1, 64-5+1) = (297, 60)\n",
        "\n",
        "        # apply global max pooling along such that the size is (297,1)\n",
        "        self.pool1 = nn.MaxPool2d((1, QUESTION_LEN-5+1))\n",
        "        self.pool2 = nn.MaxPool2d((1, CANDIDATE_LEN-5+1))\n",
        "\n",
        "        # output size of pool1 = (297,1)\n",
        "        # output size of pool2 = (297,1)\n",
        "\n",
        "        # concatenate the output of pool1 and pool2 \n",
        "        # output size of concat = (297+297, 1) = (594, 1)\n",
        "\n",
        "        # apply RNN on the concatenated output\n",
        "        self.rnn = nn.LSTM(594, 594, 1, batch_first=True, bidirectional=True)\n",
        "\n",
        "        # classify the output of RNN as two classes\n",
        "        self.fc = nn.Linear(2*594, 2)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self,q,c):\n",
        "        # q = q.view(-1, 1, 301, 32)\n",
        "        # c = c.view(-1, 1, 301, 64)\n",
        "        q = q.view(-1, 1, 301, QUESTION_LEN)\n",
        "        c = c.view(-1, 1, 301, CANDIDATE_LEN)\n",
        "        q = F.relu(self.conv1(q))\n",
        "        c = F.relu(self.conv2(c))\n",
        "        q = self.pool1(q)\n",
        "        c = self.pool2(c)\n",
        "        q = q.view(-1, 297)\n",
        "        c = c.view(-1, 297)\n",
        "        mul = torch.mul(q,c)\n",
        "        sub = torch.sub(q,c)\n",
        "        x = torch.cat((mul,sub),1)\n",
        "        # x size = (1, 594)\n",
        "        x = x.view(-1, 1, 594)\n",
        "        x, _ = self.rnn(x)\n",
        "        x = x.view(-1, 2*594)\n",
        "        x = self.fc(x)\n",
        "        # x size = (-1, 2)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BiVgX9HGXahm"
      },
      "outputs": [],
      "source": [
        "# train the model with batc size of 64\n",
        "from tqdm import trange\n",
        "def train(model,qcl,questions_emb,candidates_emb,labels,model_name,epochs=3):\n",
        "  # define the model\n",
        "  # define the loss function\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  # define the optimizer\n",
        "  optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "  # train the model on qcl ( question_embedding, candidate_embedding, label)\n",
        "\n",
        "  for epoch in trange(epochs,desc='Epochs'):  # loop over the dataset multiple times\n",
        "      running_loss = []\n",
        "      for i in range(0,len(qcl),64):\n",
        "      \n",
        "          questions = questions_emb[i:i+64]\n",
        "          candidates = candidates_emb[i:i+64]\n",
        "          labels_64 = labels[i:i+64]\n",
        "\n",
        "\n",
        "          # shape of question = (64, 301, 32)\n",
        "          # shape of candidate = (64, 301, 64)\n",
        "          # shape of label = (64,)\n",
        "          \n",
        "          # convert question to numpy array and change the size to (64,32,301)\n",
        "\n",
        "          questions = questions.reshape(-1,QUESTION_LEN,301)\n",
        "          # convert candidate to numpy array and change the size to (64,64,301)\n",
        "          candidates = candidates.reshape(-1,CANDIDATE_LEN,301)\n",
        "\n",
        "          # convert question to torch tensor\n",
        "          questions = torch.from_numpy(questions)\n",
        "          # convert candidates to torch tensor\n",
        "          candidates = torch.from_numpy(candidates)\n",
        "          # convert label to torch tensor\n",
        "\n",
        "          # zero the parameter gradients\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          # forward + backward + optimize\n",
        "          outputs = model(questions, candidates)\n",
        "          loss = criterion(outputs, torch.from_numpy(labels_64))\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          # print statistics\n",
        "          running_loss.append(loss.item())\n",
        "\n",
        "      # uncomment if you want to find loss for each epoch\n",
        "      #print(f\"Epoch : {epoch} , loss : {np.mean(running_loss)}\")    \n",
        "      torch.save(model.state_dict(),model_name+\"_\"+str(epoch)+\".pt\")\n",
        "  return model\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aspLxVu5jauN"
      },
      "outputs": [],
      "source": [
        "def metric(model,pr_emb_question_candidate_pairs):\n",
        "    model.eval()\n",
        "\n",
        "    precisions = []\n",
        "    ranks = []\n",
        "\n",
        "\n",
        "    # extract question and candidate embeddings\n",
        "    for q in pr_emb_question_candidate_pairs:\n",
        "        real_labels = []\n",
        "        predicted_scores = []\n",
        "        for c_ind,c in enumerate(q):\n",
        "            \n",
        "\n",
        "            candidate_embedding = np.array(c[1])\n",
        "            real_labels.append(c[2])\n",
        "            # shape of qe = (1, 301, 32)\n",
        "            # shape of c = (1, 301, 64)\n",
        "            q_emb = np.array(c[0])\n",
        "            q_emb = q_emb.reshape(1,QUESTION_LEN,301)\n",
        "            candidate_embedding = candidate_embedding.reshape(1,CANDIDATE_LEN,301)\n",
        "            # convert q_emb to torch tensor\n",
        "            q_emb = torch.from_numpy(q_emb)\n",
        "            # convert c to torch tensor\n",
        "            candidate_embedding = torch.from_numpy(candidate_embedding)\n",
        "            # forward\n",
        "            outputs = model(q_emb, candidate_embedding)\n",
        "            outputs = torch.nn.functional.softmax(outputs, dim=1)\n",
        "            # convert outputs to numpy array\n",
        "            outputs = outputs.detach().numpy()\n",
        "            predicted_scores.append(outputs)\n",
        "\n",
        "        \n",
        "        real_labels = np.array(real_labels)\n",
        "        question_real_labels_indices = np.where(real_labels == 1)[0]\n",
        "        predicted_scores = np.array(predicted_scores)\n",
        "        # print(predicted_scores.shape)\n",
        "        predicted_scores = predicted_scores.squeeze(axis=1)\n",
        "        # print(predicted_scores.shape)\n",
        "        predicted_scores = predicted_scores[:,1] - predicted_scores[:,0]\n",
        "        predicted_scores = np.array(predicted_scores)\n",
        "        sorted_indices = np.argsort(predicted_scores)\n",
        "        sorted_indices = sorted_indices[::-1]\n",
        "        for i in range(len(sorted_indices)):\n",
        "            if sorted_indices[i] in question_real_labels_indices:\n",
        "                sorted_indices[i] = -1\n",
        "\n",
        "        precision = 0\n",
        "        rank = 0\n",
        "        c = 0\n",
        "        for i,ind in enumerate(sorted_indices):\n",
        "            if ind == -1:\n",
        "                rank = 1/(i+1)\n",
        "                c += 1\n",
        "                precision += (c/(i+1))\n",
        "        \n",
        "        \n",
        "        \n",
        "        precision = precision/c\n",
        "        precisions.append(precision)\n",
        "        ranks.append(rank)\n",
        "    \n",
        "\n",
        "        \n",
        "    model.train()\n",
        "    return np.mean(precisions), np.mean(ranks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xR70llP0x22R"
      },
      "outputs": [],
      "source": [
        "# Training all models\n",
        "models_names = [\"CNN_RNN\", \"CNN_BiRNN\", \"CNN_LSTM\", \"CNN_BiLSTM\"]\n",
        "models = [CNN_RNN(), CNN_BiRNN(), CNN_LSTM(), CNN_BiLSTM()]\n",
        "\n",
        "MAP_dict_train = {}\n",
        "for model_name in models_names : \n",
        "  MAP_dict_train[model_name] = {}\n",
        "\n",
        "MRR_dict_train = {}\n",
        "for model_name in models_names : \n",
        "  MRR_dict_train[model_name] = {}\n",
        "\n",
        "MAP_dict_test = {}\n",
        "for model_name in models_names :\n",
        "    MAP_dict_test[model_name] = {}\n",
        "\n",
        "MRR_dict_test = {}\n",
        "for model_name in models_names :\n",
        "    MRR_dict_test[model_name] = {}\n",
        "\n",
        "MAP_dict_dev = {}\n",
        "for model_name in models_names :\n",
        "    MAP_dict_dev[model_name] = {}\n",
        "\n",
        "MRR_dict_dev = {}\n",
        "for model_name in models_names :\n",
        "    MRR_dict_dev[model_name] = {}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfG0K1op1WUL",
        "outputId": "9affcc3c-8108-45d8-ffee-9035f781bddd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs:  10%|█         | 1/10 [00:29<04:29, 29.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 0 , loss : 0.3542009859173386\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  20%|██        | 2/10 [00:55<03:40, 27.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 1 , loss : 0.32326814311522023\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  30%|███       | 3/10 [01:25<03:20, 28.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 2 , loss : 0.31664973972020327\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  40%|████      | 4/10 [01:51<02:45, 27.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 3 , loss : 0.31319604571218845\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  50%|█████     | 5/10 [02:17<02:15, 27.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 4 , loss : 0.31094001641979924\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  60%|██████    | 6/10 [02:45<01:49, 27.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 5 , loss : 0.3091335436812154\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  70%|███████   | 7/10 [03:11<01:20, 26.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 6 , loss : 0.3074942738921554\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  80%|████████  | 8/10 [03:37<00:53, 26.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 7 , loss : 0.3060744398170047\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  90%|█████████ | 9/10 [04:05<00:26, 26.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 8 , loss : 0.30485602650377486\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 100%|██████████| 10/10 [04:33<00:00, 27.31s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 9 , loss : 0.3034700431205608\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs:  10%|█         | 1/10 [00:29<04:26, 29.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 0 , loss : 0.3623289163465853\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  20%|██        | 2/10 [00:57<03:49, 28.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 1 , loss : 0.32147297969570865\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  30%|███       | 3/10 [01:25<03:17, 28.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 2 , loss : 0.3129872759183248\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  40%|████      | 4/10 [01:56<02:57, 29.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 3 , loss : 0.30933433561413376\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  50%|█████     | 5/10 [02:24<02:24, 28.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 4 , loss : 0.30661370831507223\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  60%|██████    | 6/10 [02:54<01:56, 29.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 5 , loss : 0.30425712642846287\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  70%|███████   | 7/10 [03:21<01:25, 28.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 6 , loss : 0.3022156877650155\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  80%|████████  | 8/10 [03:49<00:56, 28.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 7 , loss : 0.3005908070890992\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  90%|█████████ | 9/10 [04:19<00:28, 28.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 8 , loss : 0.29926517373985717\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 100%|██████████| 10/10 [04:48<00:00, 28.88s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 9 , loss : 0.2981582988191534\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs:  10%|█         | 1/10 [00:33<05:00, 33.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 0 , loss : 0.3783370692420889\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  20%|██        | 2/10 [01:05<04:19, 32.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 1 , loss : 0.34498193672409766\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  30%|███       | 3/10 [01:38<03:48, 32.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 2 , loss : 0.32607247597641414\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  40%|████      | 4/10 [02:09<03:13, 32.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 3 , loss : 0.31930566286599193\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  50%|█████     | 5/10 [02:42<02:41, 32.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 4 , loss : 0.3153696306325771\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  60%|██████    | 6/10 [03:14<02:08, 32.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 5 , loss : 0.31196557934637426\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  70%|███████   | 7/10 [03:45<01:35, 31.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 6 , loss : 0.3091528064674801\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  80%|████████  | 8/10 [04:18<01:04, 32.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 7 , loss : 0.3067969419338085\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  90%|█████████ | 9/10 [04:50<00:32, 32.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 8 , loss : 0.3048660252933149\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 100%|██████████| 10/10 [05:24<00:00, 32.49s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 9 , loss : 0.30328126461417587\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs:  10%|█         | 1/10 [00:38<05:42, 38.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 0 , loss : 0.37800649713586876\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  20%|██        | 2/10 [01:17<05:11, 38.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 1 , loss : 0.327559866949364\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  30%|███       | 3/10 [01:57<04:35, 39.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 2 , loss : 0.3188148311994694\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  40%|████      | 4/10 [02:37<03:56, 39.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 3 , loss : 0.31446392834186554\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  50%|█████     | 5/10 [03:15<03:14, 38.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 4 , loss : 0.3116777307457394\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  60%|██████    | 6/10 [03:54<02:36, 39.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 5 , loss : 0.3095902776276624\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  70%|███████   | 7/10 [04:34<01:57, 39.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 6 , loss : 0.30794614730057895\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  80%|████████  | 8/10 [05:14<01:18, 39.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 7 , loss : 0.3064044333166546\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  90%|█████████ | 9/10 [05:52<00:39, 39.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 8 , loss : 0.30500713962095755\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 100%|██████████| 10/10 [06:31<00:00, 39.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 9 , loss : 0.3037599743516357\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(models)):\n",
        "    train(models[i],qcl_train,questions_emb_train,candidates_emb_train,labels_train,models_names[i],epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UD0eDQQn1Yo6",
        "outputId": "039d91ce-3d5f-4c2e-a0df-e0f6cb963911"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computing train MAP and MRR for CNN_RNN:  10%|█         | 1/10 [00:14<02:13, 14.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_RNN_0.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rComputing train MAP and MRR for CNN_RNN:  20%|██        | 2/10 [00:28<01:51, 13.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_RNN_1.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rComputing train MAP and MRR for CNN_RNN:  30%|███       | 3/10 [00:41<01:35, 13.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_RNN_2.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rComputing train MAP and MRR for CNN_RNN:  40%|████      | 4/10 [00:56<01:25, 14.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_RNN_3.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rComputing train MAP and MRR for CNN_RNN:  50%|█████     | 5/10 [01:10<01:10, 14.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_RNN_4.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rComputing train MAP and MRR for CNN_RNN:  60%|██████    | 6/10 [01:23<00:55, 13.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_RNN_5.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rComputing train MAP and MRR for CNN_RNN:  70%|███████   | 7/10 [01:37<00:41, 13.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_RNN_6.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rComputing train MAP and MRR for CNN_RNN:  80%|████████  | 8/10 [01:50<00:27, 13.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_RNN_7.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rComputing train MAP and MRR for CNN_RNN:  90%|█████████ | 9/10 [02:05<00:13, 14.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_RNN_8.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computing train MAP and MRR for CNN_RNN: 100%|██████████| 10/10 [02:18<00:00, 13.88s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_RNN_9.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computing train MAP and MRR for CNN_BiRNN:  10%|█         | 1/10 [00:16<02:31, 16.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_BiRNN_0.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rComputing train MAP and MRR for CNN_BiRNN:  20%|██        | 2/10 [00:33<02:14, 16.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_BiRNN_1.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rComputing train MAP and MRR for CNN_BiRNN:  30%|███       | 3/10 [00:51<01:59, 17.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_BiRNN_2.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rComputing train MAP and MRR for CNN_BiRNN:  40%|████      | 4/10 [01:10<01:48, 18.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_BiRNN_3.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rComputing train MAP and MRR for CNN_BiRNN:  50%|█████     | 5/10 [01:27<01:28, 17.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_BiRNN_4.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rComputing train MAP and MRR for CNN_BiRNN:  60%|██████    | 6/10 [01:44<01:09, 17.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_BiRNN_5.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rComputing train MAP and MRR for CNN_BiRNN:  70%|███████   | 7/10 [02:00<00:50, 16.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_BiRNN_6.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rComputing train MAP and MRR for CNN_BiRNN:  80%|████████  | 8/10 [02:19<00:35, 17.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_BiRNN_7.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rComputing train MAP and MRR for CNN_BiRNN:  90%|█████████ | 9/10 [02:36<00:17, 17.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_BiRNN_8.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computing train MAP and MRR for CNN_BiRNN: 100%|██████████| 10/10 [02:53<00:00, 17.33s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_BiRNN_9.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computing train MAP and MRR for CNN_LSTM: 100%|██████████| 10/10 [04:01<00:00, 24.19s/it]\n",
            "Computing train MAP and MRR for CNN_BiLSTM: 100%|██████████| 10/10 [06:19<00:00, 37.91s/it]\n"
          ]
        }
      ],
      "source": [
        "for i in trange(10,desc=\"Computing train MAP and MRR for CNN_RNN\"):\n",
        "    model = CNN_RNN()\n",
        "    model.load_state_dict(torch.load(\"CNN_RNN_\"+str(i)+\".pt\"))\n",
        "    precision, rank = metric(model,pr_emb_question_candidate_pairs_train)\n",
        "    print(\"CNN_RNN_\"+str(i)+\".pt\")\n",
        "    \n",
        "    MAP_dict_train['CNN_RNN'][i] = precision\n",
        "    MRR_dict_train['CNN_RNN'][i] = rank\n",
        "\n",
        "for i in trange(10,desc=\"Computing train MAP and MRR for CNN_BiRNN\"):\n",
        "    model = CNN_BiRNN()\n",
        "    model.load_state_dict(torch.load(\"CNN_BiRNN_\"+str(i)+\".pt\"))\n",
        "    precision, rank = metric(model,pr_emb_question_candidate_pairs_train)\n",
        "    print(\"CNN_BiRNN_\"+str(i)+\".pt\")\n",
        "    \n",
        "    MAP_dict_train['CNN_BiRNN'][i] = precision\n",
        "    MRR_dict_train['CNN_BiRNN'][i] = rank\n",
        "\n",
        "\n",
        "for i in trange(10,desc=\"Computing train MAP and MRR for CNN_LSTM\"):\n",
        "    model = CNN_LSTM()\n",
        "    model.load_state_dict(torch.load(\"CNN_LSTM_\"+str(i)+\".pt\"))\n",
        "    precision, rank = metric(model,pr_emb_question_candidate_pairs_train)\n",
        "    \n",
        "    \n",
        "    MAP_dict_train['CNN_LSTM'][i] = precision\n",
        "    MRR_dict_train['CNN_LSTM'][i] = rank\n",
        "\n",
        "for i in trange(10,desc=\"Computing train MAP and MRR for CNN_BiLSTM\"):\n",
        "    model = CNN_BiLSTM()\n",
        "    model.load_state_dict(torch.load(\"CNN_BiLSTM_\"+str(i)+\".pt\"))\n",
        "    precision, rank = metric(model,pr_emb_question_candidate_pairs_train)\n",
        "    \n",
        "    MAP_dict_train['CNN_BiLSTM'][i] = precision\n",
        "    MRR_dict_train['CNN_BiLSTM'][i] = rank\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXWDOyQv1fUP",
        "outputId": "9d43d26e-59d6-48c2-96fe-5efc34b78816"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computing dev MAP and MRR for CNN_RNN:  10%|█         | 1/10 [00:02<00:19,  2.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_RNN_0.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rComputing dev MAP and MRR for CNN_RNN:  20%|██        | 2/10 [00:04<00:16,  2.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_RNN_1.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rComputing dev MAP and MRR for CNN_RNN:  30%|███       | 3/10 [00:06<00:14,  2.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_RNN_2.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rComputing dev MAP and MRR for CNN_RNN:  40%|████      | 4/10 [00:09<00:14,  2.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_RNN_3.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rComputing dev MAP and MRR for CNN_RNN:  50%|█████     | 5/10 [00:11<00:11,  2.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_RNN_4.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rComputing dev MAP and MRR for CNN_RNN:  60%|██████    | 6/10 [00:13<00:08,  2.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_RNN_5.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rComputing dev MAP and MRR for CNN_RNN:  70%|███████   | 7/10 [00:15<00:06,  2.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_RNN_6.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rComputing dev MAP and MRR for CNN_RNN:  80%|████████  | 8/10 [00:17<00:04,  2.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_RNN_7.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rComputing dev MAP and MRR for CNN_RNN:  90%|█████████ | 9/10 [00:19<00:02,  2.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_RNN_8.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computing dev MAP and MRR for CNN_RNN: 100%|██████████| 10/10 [00:21<00:00,  2.12s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_RNN_9.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computing dev MAP and MRR for CNN_BiRNN:  10%|█         | 1/10 [00:02<00:22,  2.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_BiRNN_0.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rComputing dev MAP and MRR for CNN_BiRNN:  20%|██        | 2/10 [00:04<00:19,  2.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_BiRNN_1.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rComputing dev MAP and MRR for CNN_BiRNN:  30%|███       | 3/10 [00:07<00:16,  2.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_BiRNN_2.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rComputing dev MAP and MRR for CNN_BiRNN:  40%|████      | 4/10 [00:09<00:13,  2.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_BiRNN_3.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rComputing dev MAP and MRR for CNN_BiRNN:  50%|█████     | 5/10 [00:11<00:11,  2.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_BiRNN_4.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rComputing dev MAP and MRR for CNN_BiRNN:  60%|██████    | 6/10 [00:13<00:09,  2.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_BiRNN_5.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rComputing dev MAP and MRR for CNN_BiRNN:  70%|███████   | 7/10 [00:16<00:06,  2.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_BiRNN_6.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rComputing dev MAP and MRR for CNN_BiRNN:  80%|████████  | 8/10 [00:18<00:04,  2.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_BiRNN_7.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rComputing dev MAP and MRR for CNN_BiRNN:  90%|█████████ | 9/10 [00:20<00:02,  2.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_BiRNN_8.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computing dev MAP and MRR for CNN_BiRNN: 100%|██████████| 10/10 [00:23<00:00,  2.31s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_BiRNN_9.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computing dev MAP and MRR for CNN_LSTM: 100%|██████████| 10/10 [00:31<00:00,  3.14s/it]\n",
            "Computing dev MAP and MRR for CNN_BiLSTM: 100%|██████████| 10/10 [00:51<00:00,  5.12s/it]\n"
          ]
        }
      ],
      "source": [
        "for i in trange(10,desc=\"Computing dev MAP and MRR for CNN_RNN\"):\n",
        "    model = CNN_RNN()\n",
        "    model.load_state_dict(torch.load(\"CNN_RNN_\"+str(i)+\".pt\"))\n",
        "    precision, rank = metric(model,pr_emb_question_candidate_pairs_dev)\n",
        "    print(\"CNN_RNN_\"+str(i)+\".pt\")\n",
        "    \n",
        "    MAP_dict_dev['CNN_RNN'][i] = precision\n",
        "    MRR_dict_dev['CNN_RNN'][i] = rank\n",
        "\n",
        "for i in trange(10,desc=\"Computing dev MAP and MRR for CNN_BiRNN\"):\n",
        "    model = CNN_BiRNN()\n",
        "    model.load_state_dict(torch.load(\"CNN_BiRNN_\"+str(i)+\".pt\"))\n",
        "    precision, rank = metric(model,pr_emb_question_candidate_pairs_dev)\n",
        "    print(\"CNN_BiRNN_\"+str(i)+\".pt\")\n",
        "    \n",
        "    MAP_dict_dev['CNN_BiRNN'][i] = precision\n",
        "    MRR_dict_dev['CNN_BiRNN'][i] = rank\n",
        "\n",
        "\n",
        "for i in trange(10,desc=\"Computing dev MAP and MRR for CNN_LSTM\"):\n",
        "    model = CNN_LSTM()\n",
        "    model.load_state_dict(torch.load(\"CNN_LSTM_\"+str(i)+\".pt\"))\n",
        "    precision, rank = metric(model,pr_emb_question_candidate_pairs_dev)\n",
        "    \n",
        "    \n",
        "    MAP_dict_dev['CNN_LSTM'][i] = precision\n",
        "    MRR_dict_dev['CNN_LSTM'][i] = rank\n",
        "\n",
        "for i in trange(10,desc=\"Computing dev MAP and MRR for CNN_BiLSTM\"):\n",
        "    model = CNN_BiLSTM()\n",
        "    model.load_state_dict(torch.load(\"CNN_BiLSTM_\"+str(i)+\".pt\"))\n",
        "    precision, rank = metric(model,pr_emb_question_candidate_pairs_dev)\n",
        "    \n",
        "    MAP_dict_dev['CNN_BiLSTM'][i] = precision\n",
        "    MRR_dict_dev['CNN_BiLSTM'][i] = rank\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpSI13Id1ghP",
        "outputId": "2464897c-d03c-4cd6-8c4a-90bc64c58af4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computing test MAP and MRR for CNN_RNN:  10%|█         | 1/10 [00:04<00:39,  4.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_RNN_0.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rComputing test MAP and MRR for CNN_RNN:  20%|██        | 2/10 [00:08<00:32,  4.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_RNN_1.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rComputing test MAP and MRR for CNN_RNN:  30%|███       | 3/10 [00:11<00:26,  3.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_RNN_2.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rComputing test MAP and MRR for CNN_RNN:  40%|████      | 4/10 [00:15<00:23,  3.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_RNN_3.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rComputing test MAP and MRR for CNN_RNN:  50%|█████     | 5/10 [00:19<00:19,  3.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_RNN_4.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rComputing test MAP and MRR for CNN_RNN:  60%|██████    | 6/10 [00:23<00:15,  3.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_RNN_5.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rComputing test MAP and MRR for CNN_RNN:  70%|███████   | 7/10 [00:28<00:12,  4.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_RNN_6.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rComputing test MAP and MRR for CNN_RNN:  80%|████████  | 8/10 [00:32<00:08,  4.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_RNN_7.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rComputing test MAP and MRR for CNN_RNN:  90%|█████████ | 9/10 [00:35<00:03,  3.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_RNN_8.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computing test MAP and MRR for CNN_RNN: 100%|██████████| 10/10 [00:39<00:00,  3.96s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_RNN_9.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computing test MAP and MRR for CNN_BiRNN:  10%|█         | 1/10 [00:04<00:40,  4.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_BiRNN_0.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rComputing test MAP and MRR for CNN_BiRNN:  20%|██        | 2/10 [00:09<00:36,  4.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_BiRNN_1.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rComputing test MAP and MRR for CNN_BiRNN:  30%|███       | 3/10 [00:13<00:31,  4.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_BiRNN_2.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rComputing test MAP and MRR for CNN_BiRNN:  40%|████      | 4/10 [00:18<00:27,  4.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_BiRNN_3.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rComputing test MAP and MRR for CNN_BiRNN:  50%|█████     | 5/10 [00:22<00:22,  4.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_BiRNN_4.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rComputing test MAP and MRR for CNN_BiRNN:  60%|██████    | 6/10 [00:27<00:18,  4.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_BiRNN_5.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rComputing test MAP and MRR for CNN_BiRNN:  70%|███████   | 7/10 [00:31<00:13,  4.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_BiRNN_6.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rComputing test MAP and MRR for CNN_BiRNN:  80%|████████  | 8/10 [00:36<00:09,  4.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_BiRNN_7.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rComputing test MAP and MRR for CNN_BiRNN:  90%|█████████ | 9/10 [00:41<00:04,  4.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_BiRNN_8.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computing test MAP and MRR for CNN_BiRNN: 100%|██████████| 10/10 [00:45<00:00,  4.59s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_BiRNN_9.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computing test MAP and MRR for CNN_LSTM: 100%|██████████| 10/10 [01:05<00:00,  6.60s/it]\n",
            "Computing test MAP and MRR for CNN_BiLSTM: 100%|██████████| 10/10 [01:44<00:00, 10.44s/it]\n"
          ]
        }
      ],
      "source": [
        "for i in trange(10,desc=\"Computing test MAP and MRR for CNN_RNN\"):\n",
        "    model = CNN_RNN()\n",
        "    model.load_state_dict(torch.load(\"CNN_RNN_\"+str(i)+\".pt\"))\n",
        "    precision, rank = metric(model,pr_emb_question_candidate_pairs_test)\n",
        "    print(\"CNN_RNN_\"+str(i)+\".pt\")\n",
        "    \n",
        "    MAP_dict_test['CNN_RNN'][i] = precision\n",
        "    MRR_dict_test['CNN_RNN'][i] = rank\n",
        "\n",
        "for i in trange(10,desc=\"Computing test MAP and MRR for CNN_BiRNN\"):\n",
        "    model = CNN_BiRNN()\n",
        "    model.load_state_dict(torch.load(\"CNN_BiRNN_\"+str(i)+\".pt\"))\n",
        "    precision, rank = metric(model,pr_emb_question_candidate_pairs_test)\n",
        "    print(\"CNN_BiRNN_\"+str(i)+\".pt\")\n",
        "    \n",
        "    MAP_dict_test['CNN_BiRNN'][i] = precision\n",
        "    MRR_dict_test['CNN_BiRNN'][i] = rank\n",
        "\n",
        "\n",
        "for i in trange(10,desc=\"Computing test MAP and MRR for CNN_LSTM\"):\n",
        "    model = CNN_LSTM()\n",
        "    model.load_state_dict(torch.load(\"CNN_LSTM_\"+str(i)+\".pt\"))\n",
        "    precision, rank = metric(model,pr_emb_question_candidate_pairs_test)\n",
        "    \n",
        "    \n",
        "    MAP_dict_test['CNN_LSTM'][i] = precision\n",
        "    MRR_dict_test['CNN_LSTM'][i] = rank\n",
        "\n",
        "for i in trange(10,desc=\"Computing test MAP and MRR for CNN_BiLSTM\"):\n",
        "    model = CNN_BiLSTM()\n",
        "    model.load_state_dict(torch.load(\"CNN_BiLSTM_\"+str(i)+\".pt\"))\n",
        "    precision, rank = metric(model,pr_emb_question_candidate_pairs_test)\n",
        "    \n",
        "    MAP_dict_test['CNN_BiLSTM'][i] = precision\n",
        "    MRR_dict_test['CNN_BiLSTM'][i] = rank\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZXeEYtEEZmI"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "\n",
        "\n",
        "try:\n",
        "  geeky_file = open('MAP_dict_test', 'wb')\n",
        "  pickle.dump(MAP_dict_test, geeky_file)\n",
        "  geeky_file.close()\n",
        "  \n",
        " \n",
        "\n",
        "  geeky_file = open('MAP_dict_train', 'wb')\n",
        "  pickle.dump(MAP_dict_train, geeky_file)\n",
        "  geeky_file.close()\n",
        "\n",
        "  geeky_file = open('MAP_dict_dev', 'wb')\n",
        "  pickle.dump(MAP_dict_dev, geeky_file)\n",
        "  geeky_file.close()\n",
        "\n",
        "  geeky_file = open('MRR_dict_test', 'wb')\n",
        "  pickle.dump(MRR_dict_test, geeky_file)\n",
        "  geeky_file.close()\n",
        "  \n",
        " \n",
        "\n",
        "  geeky_file = open('MRR_dict_train', 'wb')\n",
        "  pickle.dump(MRR_dict_train, geeky_file)\n",
        "  geeky_file.close()\n",
        "\n",
        "  geeky_file = open('MRR_dict_dev', 'wb')\n",
        "  pickle.dump(MRR_dict_dev, geeky_file)\n",
        "  geeky_file.close()\n",
        "\t\n",
        "\n",
        "\t\n",
        "\n",
        "except:\n",
        "\tprint(\"Something went wrong\")\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsLVw3TAFOMM",
        "outputId": "826edd7f-572d-4d4f-bafb-8d8bf2b6dc1d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'CNN_RNN': {0: 0.6464378954378954,\n",
              "  1: 0.6692549737843856,\n",
              "  2: 0.6756396779690896,\n",
              "  3: 0.6722350094350095,\n",
              "  4: 0.6689560620665884,\n",
              "  5: 0.665622728733255,\n",
              "  6: 0.6709188478188479,\n",
              "  7: 0.6756116582763642,\n",
              "  8: 0.671871687136393,\n",
              "  9: 0.6695097823744882},\n",
              " 'CNN_BiRNN': {0: 0.6370610089257146,\n",
              "  1: 0.6431658263305321,\n",
              "  2: 0.6446063492063493,\n",
              "  3: 0.6432148629148629,\n",
              "  4: 0.6310359562006621,\n",
              "  5: 0.6287855144855145,\n",
              "  6: 0.6367024864024863,\n",
              "  7: 0.6416628038628038,\n",
              "  8: 0.6362437562437563,\n",
              "  9: 0.6391632922632922},\n",
              " 'CNN_LSTM': {0: 0.6191395966606493,\n",
              "  1: 0.6370116176221439,\n",
              "  2: 0.6387033925139187,\n",
              "  3: 0.6522914711019975,\n",
              "  4: 0.6809961623172148,\n",
              "  5: 0.683335715746242,\n",
              "  6: 0.6900503307150366,\n",
              "  7: 0.6965299589299588,\n",
              "  8: 0.6952350094350094,\n",
              "  9: 0.6942778665778665},\n",
              " 'CNN_BiLSTM': {0: 0.6178405483405484,\n",
              "  1: 0.6419860028860029,\n",
              "  2: 0.6533095825742884,\n",
              "  3: 0.6512458019105078,\n",
              "  4: 0.6546224100976421,\n",
              "  5: 0.6485308350060671,\n",
              "  6: 0.6628343388637506,\n",
              "  7: 0.664719306184012,\n",
              "  8: 0.6728018458665518,\n",
              "  9: 0.6705026862026862}}"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MRR_dict_dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StIkqRevG6ms"
      },
      "outputs": [],
      "source": [
        "with open('MRR_dict_dev', 'rb') as handle:\n",
        "    temp_dict = pickle.load(handle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wyfg9eCOZxU",
        "outputId": "25171b9a-d4e5-42a4-ba13-64cf1a2db23d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1oIQhGfbPREd"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "def load_pickle(file):\n",
        "  with open(file,'rb') as f:\n",
        "    return pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWXjDlSCPzwT"
      },
      "outputs": [],
      "source": [
        "MAP_dict_train = load_pickle('MAP_dict_train')\n",
        "MRR_dict_train = load_pickle('MRR_dict_train')\n",
        "MAP_dict_dev = load_pickle('MAP_dict_dev')\n",
        "MRR_dict_dev = load_pickle('MRR_dict_dev')\n",
        "MAP_dict_test = load_pickle('MAP_dict_test')\n",
        "MRR_dict_test = load_pickle('MRR_dict_test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNzzxtHQQu-J",
        "outputId": "0417f754-cea3-42fd-a965-6d3b2d4f40cf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'CNN_RNN': {0: 0.6253154691648091,\n",
              "  1: 0.6445816840291366,\n",
              "  2: 0.6543541742258175,\n",
              "  3: 0.6529217330912183,\n",
              "  4: 0.6550247621610499,\n",
              "  5: 0.6608472558449161,\n",
              "  6: 0.6603069431514839,\n",
              "  7: 0.6558958132881019,\n",
              "  8: 0.6514771144947431,\n",
              "  9: 0.6556331691447046},\n",
              " 'CNN_BiRNN': {0: 0.636338470902986,\n",
              "  1: 0.6388376934181824,\n",
              "  2: 0.6539765717197725,\n",
              "  3: 0.6529791975260226,\n",
              "  4: 0.6449462987104507,\n",
              "  5: 0.6438752771519508,\n",
              "  6: 0.649421364637589,\n",
              "  7: 0.6447754684637271,\n",
              "  8: 0.6397086696675736,\n",
              "  9: 0.640077015855665},\n",
              " 'CNN_LSTM': {0: 0.6138280938190247,\n",
              "  1: 0.6316922740879468,\n",
              "  2: 0.640958482948821,\n",
              "  3: 0.6484526911851242,\n",
              "  4: 0.657938262200936,\n",
              "  5: 0.6605455804986308,\n",
              "  6: 0.6636536184393047,\n",
              "  7: 0.6660470503120639,\n",
              "  8: 0.6697212244153835,\n",
              "  9: 0.6679859345186366},\n",
              " 'CNN_BiLSTM': {0: 0.6222211928098572,\n",
              "  1: 0.645006513722024,\n",
              "  2: 0.6482745245497522,\n",
              "  3: 0.6504861449022167,\n",
              "  4: 0.6668514160792035,\n",
              "  5: 0.6684986642957645,\n",
              "  6: 0.6724546409086448,\n",
              "  7: 0.6726266388316887,\n",
              "  8: 0.6713947291792771,\n",
              "  9: 0.6744421461451026}}"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MAP_dict_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfv8vSbBOd2e"
      },
      "outputs": [],
      "source": [
        "def metrics(model_name):\n",
        "  for e in range(10):\n",
        "    print(\"MRR (train): \",MRR_dict_train[model_name][e],\"MAP (train): \",MAP_dict_train[model_name][e],\"MRR (dev): \",MRR_dict_dev[model_name][e],\"MAP (dev): \",MAP_dict_dev[model_name][e],\"MRR (test): \",MRR_dict_test[model_name][e],\"MAP (test): \",MAP_dict_test[model_name][e])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arvkw0orRCtv",
        "outputId": "1a62029e-a52b-497b-b551-22d943840b73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MRR (train):  0.5614359841637723 MAP (train):  0.6161056796531179 MRR (dev):  0.6178405483405484 MAP (dev):  0.6443849927849928 MRR (test):  0.5683005188185765 MAP (test):  0.6222211928098572\n",
            "MRR (train):  0.5924844857052279 MAP (train):  0.6494269178725736 MRR (dev):  0.6419860028860029 MAP (dev):  0.6677526695526695 MRR (test):  0.5887389146858427 MAP (test):  0.645006513722024\n",
            "MRR (train):  0.5940160797318942 MAP (train):  0.6519165946768152 MRR (dev):  0.6533095825742884 MAP (dev):  0.6817429159076217 MRR (test):  0.591990321940482 MAP (test):  0.6482745245497522\n",
            "MRR (train):  0.5967267484763757 MAP (train):  0.655527462280797 MRR (dev):  0.6512458019105078 MAP (dev):  0.681679135243841 MRR (test):  0.5933007833635449 MAP (test):  0.6504861449022167\n",
            "MRR (train):  0.595154403283838 MAP (train):  0.654398853703523 MRR (dev):  0.6546224100976421 MAP (dev):  0.6852557434309756 MRR (test):  0.6094512298487195 MAP (test):  0.6668514160792035\n",
            "MRR (train):  0.5974357260565972 MAP (train):  0.6572043076973983 MRR (dev):  0.6485308350060671 MAP (dev):  0.6791641683394006 MRR (test):  0.6122462000550528 MAP (test):  0.6684986642957645\n",
            "MRR (train):  0.596949394817671 MAP (train):  0.6567526021444309 MRR (dev):  0.6628343388637506 MAP (dev):  0.6934676721970838 MRR (test):  0.615600407446917 MAP (test):  0.6724546409086448\n",
            "MRR (train):  0.5974535278230444 MAP (train):  0.6579911376452053 MRR (dev):  0.664719306184012 MAP (dev):  0.6933526395173453 MRR (test):  0.6157438774125626 MAP (test):  0.6726266388316887\n",
            "MRR (train):  0.5992443625621796 MAP (train):  0.6595276622107686 MRR (dev):  0.6728018458665518 MAP (dev):  0.7007685125332185 MRR (test):  0.6145119677601509 MAP (test):  0.6713947291792771\n",
            "MRR (train):  0.6039563248051819 MAP (train):  0.6641894839310746 MRR (dev):  0.6705026862026862 MAP (dev):  0.6991360195360196 MRR (test):  0.6169803073678872 MAP (test):  0.6744421461451026\n"
          ]
        }
      ],
      "source": [
        "metrics('CNN_BiLSTM')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a777tTgRIA1h",
        "outputId": "3dac424b-bf86-4e72-d90f-fbd002fb01fb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'CNN_RNN': {0: 0.6464378954378954,\n",
              "  1: 0.6692549737843856,\n",
              "  2: 0.6756396779690896,\n",
              "  3: 0.6722350094350095,\n",
              "  4: 0.6689560620665884,\n",
              "  5: 0.665622728733255,\n",
              "  6: 0.6709188478188479,\n",
              "  7: 0.6756116582763642,\n",
              "  8: 0.671871687136393,\n",
              "  9: 0.6695097823744882},\n",
              " 'CNN_BiRNN': {0: 0.6370610089257146,\n",
              "  1: 0.6431658263305321,\n",
              "  2: 0.6446063492063493,\n",
              "  3: 0.6432148629148629,\n",
              "  4: 0.6310359562006621,\n",
              "  5: 0.6287855144855145,\n",
              "  6: 0.6367024864024863,\n",
              "  7: 0.6416628038628038,\n",
              "  8: 0.6362437562437563,\n",
              "  9: 0.6391632922632922},\n",
              " 'CNN_LSTM': {0: 0.6191395966606493,\n",
              "  1: 0.6370116176221439,\n",
              "  2: 0.6387033925139187,\n",
              "  3: 0.6522914711019975,\n",
              "  4: 0.6809961623172148,\n",
              "  5: 0.683335715746242,\n",
              "  6: 0.6900503307150366,\n",
              "  7: 0.6965299589299588,\n",
              "  8: 0.6952350094350094,\n",
              "  9: 0.6942778665778665},\n",
              " 'CNN_BiLSTM': {0: 0.6178405483405484,\n",
              "  1: 0.6419860028860029,\n",
              "  2: 0.6533095825742884,\n",
              "  3: 0.6512458019105078,\n",
              "  4: 0.6546224100976421,\n",
              "  5: 0.6485308350060671,\n",
              "  6: 0.6628343388637506,\n",
              "  7: 0.664719306184012,\n",
              "  8: 0.6728018458665518,\n",
              "  9: 0.6705026862026862}}"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "temp_dict"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "df0893f56f349688326838aaeea0de204df53a132722cbd565e54b24a8fec5f6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
